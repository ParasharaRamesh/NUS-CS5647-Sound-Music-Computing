# Seed needs to be set at top of yaml, before objects with parameters are made
# NOTE: Seed does not guarantee replicability with CTC
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

#NOTE: changed this
output_dir: results/drop0.2x2_lr0.005_wd0.1
checkpoint_dir: !ref <output_dir>/best_ckpt
result_fn: !ref <output_dir>/results.txt

#NOTE. added this
train_valid_result_fn: !ref <output_dir>/train_valid_stats.txt
drop_p: 0.2

#NOTE: No of epochs
N_epochs: 20

#NOTE. changed this
lr: 0.005

dataloader_options:
    batch_size: 1

# Special tokens and labels
blank_index: 0
num_labels: 41 # 39 phonemes + 1 blank + 1 unknown

# Model parameters
activation: !new:torch.nn.LeakyReLU

compute_features: !new:speechbrain.lobes.features.MFCC

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: global


model: !new:speechbrain.nnet.containers.Sequential
    input_shape: [null, null, 660]  # input_size
    conv1: !name:speechbrain.nnet.complex_networks.c_CNN.CConv1d
        out_channels: 16
        kernel_size: 3
    nrm1: !name:speechbrain.nnet.complex_networks.c_normalization.CLayerNorm
    act1: !ref <activation>
    dropout1: !new:torch.nn.Dropout  # NOTE: added dropout 1
        p: !ref <drop_p>
    conv2: !name:speechbrain.nnet.complex_networks.c_CNN.CConv1d
        out_channels: 32
        kernel_size: 3
    nrm2: !name:speechbrain.nnet.complex_networks.c_normalization.CLayerNorm
    act2: !ref <activation>
    dropout2: !new:torch.nn.Dropout  # NOTE: added dropout 2
        p: !ref <drop_p>
    pooling: !new:speechbrain.nnet.pooling.Pooling1d
        pool_type: "avg"
        kernel_size: 3
    RNN: !name:speechbrain.nnet.complex_networks.c_RNN.CLiGRU
        hidden_size: 64
        bidirectional: True
    dropout3: !new:torch.nn.Dropout  # NOTE: added dropout 3
        p: !ref <drop_p>

lin: !new:speechbrain.nnet.linear.Linear
    input_size: 256
    n_neurons: !ref <num_labels>
    bias: False

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

modules:
    compute_features: !ref <compute_features>
    model: !ref <model>
    lin: !ref <lin>
    mean_var_norm: !ref <mean_var_norm>


opt_class: !name:torch.optim.AdamW
    lr: !ref <lr>
    weight_decay: 0.1 #NOTE: added weight decay


compute_cost: !name:speechbrain.nnet.losses.ctc_loss
    blank_index: !ref <blank_index>

per_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats
